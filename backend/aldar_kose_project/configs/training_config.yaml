# SDXL LoRA Fine-tuning Configuration for Aldar Kose Character

# Model Configuration
base_model: "stabilityai/stable-diffusion-xl-base-1.0"
vae_model: null  # null = use base model's VAE, or specify custom path
scheduler: "ddpm"  # Options: ddpm, ddim, pndm, euler_a

# Training Data
data_dir: "./data/images"
captions_dir: "./data/captions"
processed_dir: "./data/processed_images"
cache_dir: "./cache"

# Image Processing
resolution: 1024  # Full quality - H100 has plenty of VRAM (80GB)
center_crop: true
random_flip: false  # Set to false to maintain identity consistency

# Training Hyperparameters
batch_size: 4  # Increased from 1 - H100 can handle it (Effective batch size = 4)
gradient_accumulation_steps: 1  # No need for accumulation with H100 VRAM
learning_rate: 1.0e-4
unet_lr: 1.0e-4
text_encoder_lr: 5.0e-5
lr_scheduler: "constant_with_warmup"
lr_warmup_steps: 100
max_steps: 3000  # Full training run - H100 will complete in ~15-20 minutes
max_train_epochs: null  # null = use max_steps instead

# LoRA Configuration
lora_rank: 64  # Increased to 64 - H100 has enough VRAM to handle full capacity
lora_alpha: 32  # Lower alpha for smoother training (half of rank)
lora_dropout: 0.1  # Add dropout for regularization
lora_target_modules:
  - "to_q"
  - "to_k"
  - "to_v"
  - "to_out.0"  # Train all attention modules for best quality
train_text_encoder: true  # Enable text encoder training - massive quality improvement with H100

# Memory & Precision
precision: "bf16"  # Use bf16 - H100 has hardware support (faster + stable)
mixed_precision: "bf16"
gradient_checkpointing: false  # Disable - H100 doesn't need it (80GB is plenty)
enable_xformers: true  # Enable for faster attention - H100 loves this
use_8bit_adam: false  # Disable - use regular AdamW (faster on H100, memory is not constrained)
enable_cpu_offload: false  # Disable - keep everything on GPU (H100 has 80GB!)

# Regularization
noise_offset: 0.1  # Improves dark/light image generation
snr_gamma: 5.0  # Min-SNR weighting strategy
prior_preservation: false
prior_preservation_weight: 1.0

# Checkpointing & Logging
output_dir: "./outputs/aldar_kose_lora"
checkpoint_dir: "./outputs/checkpoints"
save_every: 100  # Save checkpoint every 100 steps (faster training, less I/O)
save_total_limit: 5  # Keep only last N checkpoints
resume_from_checkpoint: null  # Path to checkpoint or "latest"

# Weights & Biases
use_wandb: false  # Disabled - using terminal logging and local files instead
wandb_project: "aldar_kose_finetune"
wandb_entity: null  # Your wandb username/team
wandb_run_name: null  # Auto-generated if null
log_every: 10  # Log metrics every N steps

# Validation & Sampling
validate_every: 50  # Generate validation samples every N steps
num_validation_images: 1
validation_prompts:
  - "3D render of aldar_kose_man smiling, high quality, detailed"
  - "aldar_kose_man in traditional Kazakh clothing, 3D animation"
  - "portrait of aldar_kose_man, cinematic lighting"
  - "aldar_kose_man character, full body, white background"
validation_seeds: [42, 123, 456, 789]

# Identity Consistency Evaluation
compute_identity_similarity: true  # Compute CLIP similarity for validation
reference_image_path: null  # Path to reference image for similarity comparison

# Miscellaneous
seed: 42
num_workers: 0  # Set to 0 for Windows - multiprocessing issue with DataLoader
max_grad_norm: 1.0  # Gradient clipping
adam_beta1: 0.9
adam_beta2: 0.999
adam_weight_decay: 0.01
adam_epsilon: 1.0e-8

# Trigger Token (used in captions)
trigger_token: "aldar_kose_man"

# üöÄ Quick Start Guide - Reference-Guided Storyboard

## üéØ What You'll Do
Generate a storyboard with **maximum character consistency** using IP-Adapter + ControlNet.

---

## üìã Prerequisites

‚úÖ You already have:
- Trained LoRA checkpoint-400
- RunPod H100 instance running
- Base dependencies installed

---

## üîß Step-by-Step Setup (First Time Only)

### 1. SSH into your RunPod instance

### 2. Navigate to project directory
```bash
cd /workspace/SexyAldarKose/backend/aldar_kose_project
```

### 3. Pull latest code
```bash
git pull origin main
```

### 4. Install reference-guided dependencies
```bash
bash setup_ref_guided.sh
```

This will install:
- ControlNet preprocessors (for pose detection)
- IP-Adapter (for facial reference injection)
- InsightFace (for face detection)

**Time**: ~5-10 minutes  
**One-time setup**: You only need to do this once!

---

## üé¨ Usage Examples

### Example 1: Simple Mode (What You've Been Using)
**VRAM**: 8-10GB | **Speed**: Fast | **Quality**: Good

```bash
python scripts/prompt_storyboard.py \
    --lora-path outputs/checkpoints/checkpoint-400 \
    --story "Aldar Kose riding his horse across the steppe towards his yurt at sunset"
```

**Output**: `outputs/prompt_storyboard_TIMESTAMP/`
- 6-10 frames with good consistency
- Uses LoRA + CLIP validation

---

### Example 2: Reference-Guided Mode (NEW! Maximum Quality)
**VRAM**: 16-20GB | **Speed**: Moderate | **Quality**: Excellent

```bash
python scripts/prompt_storyboard.py \
    --lora-path outputs/checkpoints/checkpoint-400 \
    --story "Aldar Kose riding his horse across the steppe towards his yurt at sunset" \
    --use-ref-guided
```

**Output**: `outputs/prompt_storyboard_TIMESTAMP/`
- 6-10 frames with excellent facial consistency
- Frame 1 establishes identity
- Frames 2+ use Frame 1 as facial reference
- Includes pose skeleton maps

**What's Different?**
- ‚ú® Face from Frame 1 is injected into all subsequent frames
- ‚ú® Better facial consistency (CLIP scores: 0.75-0.85 vs 0.68-0.72)
- ‚ú® Pose control via ControlNet
- ‚è±Ô∏è Takes 2x longer but quality is worth it

---

### Example 3: Custom Story with More Frames
```bash
python scripts/prompt_storyboard.py \
    --lora-path outputs/checkpoints/checkpoint-400 \
    --story "Aldar Kose cleverly tricks a wealthy merchant in the marketplace, steals his horse, and rides away laughing" \
    --use-ref-guided \
    --num-frames 10 \
    --output-dir outputs/merchant_trick
```

---

### Example 4: Higher Quality Settings
```bash
python scripts/prompt_storyboard.py \
    --lora-path outputs/checkpoints/checkpoint-400 \
    --story "Your story here" \
    --use-ref-guided \
    --num-inference-steps 60 \
    --guidance-scale 8.0 \
    --base-seed 123
```

---

## üìä Comparing Outputs

### After Generation, Check:

**1. Scene Breakdown** (`scene_breakdown.json`):
```json
{
  "story": "Your story",
  "num_frames": 8,
  "scenes": [
    {"frame": 1, "description": "aldar_kose_man riding horse, steppe, close-up"},
    ...
  ]
}
```

**2. Report** (`report.json`):
```json
{
  "average_consistency": 0.782,  // Higher = better consistency
  "min_consistency": 0.701,
  "pipeline": "reference_guided",
  "features": {
    "ip_adapter": true,
    "controlnet": true
  }
}
```

**3. Generated Images**:
- `frame_001.png` - Reference frame (establishes identity)
- `frame_002.png` - Frame 2 (uses reference)
- `frame_003.png` - Frame 3 (uses reference)
- ...
- `pose_001.png` - Pose skeleton (if ControlNet used)
- `pose_002.png` - Pose skeleton
- ...

---

## üé® Story Ideas to Test

### Simple Stories (6-7 frames):
```bash
--story "Aldar Kose riding his horse to his yurt at sunset"
--story "Aldar Kose drinks tea inside his yurt"
--story "Aldar Kose walks through the marketplace"
```

### Medium Stories (8-9 frames):
```bash
--story "Aldar Kose meets a merchant, they talk, and he tricks him out of gold coins"
--story "Aldar Kose rides across the steppe, sees eagles flying, arrives at a village"
```

### Complex Stories (10 frames):
```bash
--story "Aldar Kose tricks a wealthy merchant in the marketplace, steals his magnificent horse, rides across the steppe laughing, and returns home to his yurt victorious"
```

---

## üîç Quality Comparison Commands

### Test Both Modes Side-by-Side:

**Simple Mode**:
```bash
python scripts/prompt_storyboard.py \
    --lora-path outputs/checkpoints/checkpoint-400 \
    --story "Aldar Kose riding across the steppe" \
    --output-dir outputs/test_simple \
    --base-seed 42
```

**Reference-Guided Mode**:
```bash
python scripts/prompt_storyboard.py \
    --lora-path outputs/checkpoints/checkpoint-400 \
    --story "Aldar Kose riding across the steppe" \
    --use-ref-guided \
    --output-dir outputs/test_ref_guided \
    --base-seed 42
```

Then compare:
- Face consistency across frames
- CLIP scores in `report.json`
- Overall visual quality

---

## üìà Expected Results

### Simple Mode:
```
Frame 1: ‚úì Good face
Frame 2: ‚úì Similar face (CLIP: 0.68)
Frame 3: ‚úì Similar face (CLIP: 0.70)
Frame 4: ‚ö†Ô∏è Slight variation (CLIP: 0.65) ‚Üí regenerated
Frame 5: ‚úì Similar face (CLIP: 0.71)
...
```

### Reference-Guided Mode:
```
Frame 1: ‚úì Reference face established
Frame 2: ‚ú® Exact face from Frame 1 (CLIP: 0.78)
Frame 3: ‚ú® Exact face from Frame 1 (CLIP: 0.81)
Frame 4: ‚ú® Exact face from Frame 1 (CLIP: 0.76)
Frame 5: ‚ú® Exact face from Frame 1 (CLIP: 0.83)
...
```

---

## üêõ Troubleshooting

### "IP-Adapter not found" Warning
**Cause**: IP-Adapter not installed  
**Solution**: Run `bash setup_ref_guided.sh` again

### CUDA Out of Memory (OOM)
**Cause**: H100 80GB should be enough, but check usage  
**Solution**: 
```bash
# Check VRAM usage
nvidia-smi

# Reduce inference steps if needed
--num-inference-steps 30
```

### "No module named 'controlnet_aux'"
**Cause**: ControlNet dependencies not installed  
**Solution**: 
```bash
pip install controlnet-aux
```

### Low Quality / Weird Faces
**Cause**: Prompt might be too complex or contradictory  
**Solution**: 
- Simplify story description
- Ensure "close-up" and "front-facing" are implied
- Check that LoRA path is correct

### Generation Takes Too Long
**Normal**: Reference-guided mode is ~2x slower than simple mode
- Simple: 10-15s per frame
- Ref-guided: 20-30s per frame

For 8 frames:
- Simple: ~2 minutes
- Ref-guided: ~4 minutes

---

## üéØ Recommended Workflow

### Day 1: Setup & Test
```bash
# 1. Install dependencies (one-time)
bash setup_ref_guided.sh

# 2. Test simple mode (confirm working)
python scripts/prompt_storyboard.py \
    --lora-path outputs/checkpoints/checkpoint-400 \
    --story "Aldar Kose riding his horse"

# 3. Test ref-guided mode (confirm working)
python scripts/prompt_storyboard.py \
    --lora-path outputs/checkpoints/checkpoint-400 \
    --story "Aldar Kose riding his horse" \
    --use-ref-guided
```

### Day 2: Generate Stories
```bash
# Quick iterations with simple mode
python scripts/prompt_storyboard.py \
    --lora-path outputs/checkpoints/checkpoint-400 \
    --story "Story concept 1"

python scripts/prompt_storyboard.py \
    --lora-path outputs/checkpoints/checkpoint-400 \
    --story "Story concept 2"

# Final production with ref-guided
python scripts/prompt_storyboard.py \
    --lora-path outputs/checkpoints/checkpoint-400 \
    --story "Final approved story" \
    --use-ref-guided \
    --num-frames 10 \
    --num-inference-steps 60
```

---

## üì• Download Results

### From RunPod to Local Machine:

```bash
# On your local machine (Windows PowerShell)
# Replace <POD_ID> with your RunPod SSH connection

# Download specific storyboard
scp -r root@<POD_ID>:/workspace/SexyAldarKose/backend/aldar_kose_project/outputs/prompt_storyboard_20251018_123456 ./downloads/

# Or download all outputs
scp -r root@<POD_ID>:/workspace/SexyAldarKose/backend/aldar_kose_project/outputs ./downloads/
```

---

## üéì Next Steps

1. ‚úÖ **Pull latest code**: `git pull origin main`
2. ‚úÖ **Install dependencies**: `bash setup_ref_guided.sh`
3. ‚úÖ **Test simple mode**: Confirm working
4. ‚úÖ **Test ref-guided mode**: Compare quality
5. ‚úÖ **Generate your stories**: Create storyboards
6. ‚úÖ **Download results**: Get PNGs to local machine
7. ‚úÖ **Compare modes**: See which quality you prefer

---

## üÜò Need Help?

**Full Documentation**:
- `REF_GUIDED_GUIDE.md` - Complete technical guide
- `PROMPT_STORYBOARD_GUIDE.md` - Prompt-based generator docs
- `FEATURE_SUMMARY.md` - All features comparison
- `scripts/README.md` - All scripts overview

**Quick Commands**:
```bash
# Help for prompt storyboard
python scripts/prompt_storyboard.py --help

# Help for ref-guided standalone
python scripts/ref_guided_storyboard.py --help
```

---

## üí° Pro Tips

1. **Start with simple mode** for fast iterations, then use ref-guided for final production
2. **Use the same seed** (`--base-seed 42`) to compare modes fairly
3. **Check CLIP scores** in `report.json` - higher = better consistency
4. **Test different frame counts** - GPT-4 decides optimal number (6-10)
5. **Simple stories work best** - avoid overly complex descriptions
6. **Front-facing close-ups** give best facial consistency

---

**Ready to generate? Start with this command:**

```bash
cd /workspace/SexyAldarKose/backend/aldar_kose_project
git pull origin main
bash setup_ref_guided.sh
python scripts/prompt_storyboard.py \
    --lora-path outputs/checkpoints/checkpoint-400 \
    --story "Aldar Kose riding his horse across the golden steppe towards his yurt at sunset" \
    --use-ref-guided
```

üé¨ **Let's create some amazing storyboards!** üöÄ
